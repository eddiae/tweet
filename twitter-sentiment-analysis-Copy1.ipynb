{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92b885dd147dac19bd0a33db3cd0da100bd5bc23",
    "colab_type": "text",
    "id": "HTyJnqzFFjur"
   },
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9bq9NGamM9nZ"
   },
   "source": [
    "**DATASET** \n",
    "\n",
    "Here we will build our dataset with correct columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7394,
     "status": "ok",
     "timestamp": 1570965604898,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "SBXUjJ7LM6nE",
    "outputId": "dc710999-2e5d-42be-e802-558c98cb1c22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>Username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2263447667</td>\n",
       "      <td>Sun Jun 21 00:50:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TANIyasso</td>\n",
       "      <td>hilo on my mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2263447702</td>\n",
       "      <td>Sun Jun 21 00:50:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mollyisabamf</td>\n",
       "      <td>@ambiiomfg Once My House Arrest Is Over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2263448097</td>\n",
       "      <td>Sun Jun 21 00:50:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Just_Plain_Mary</td>\n",
       "      <td>i have already seen all the episodes of foren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2263448360</td>\n",
       "      <td>Sun Jun 21 00:50:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>FunkySweets</td>\n",
       "      <td>watched &amp;quot;Marley and Me&amp;quot; earlier toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2263448603</td>\n",
       "      <td>Sun Jun 21 00:50:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>vulcanella</td>\n",
       "      <td>@sassyback yes!!!! Oh but I'm here  sing very ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Sentiment         ids                          date      flag  \\\n",
       "0      0          0  2263447667  Sun Jun 21 00:50:23 PDT 2009  NO_QUERY   \n",
       "1      1          0  2263447702  Sun Jun 21 00:50:23 PDT 2009  NO_QUERY   \n",
       "2      2          0  2263448097  Sun Jun 21 00:50:27 PDT 2009  NO_QUERY   \n",
       "3      3          0  2263448360  Sun Jun 21 00:50:29 PDT 2009  NO_QUERY   \n",
       "4      4          0  2263448603  Sun Jun 21 00:50:31 PDT 2009  NO_QUERY   \n",
       "\n",
       "          Username                                               text  \n",
       "0        TANIyasso                                   hilo on my mind   \n",
       "1     mollyisabamf           @ambiiomfg Once My House Arrest Is Over   \n",
       "2  Just_Plain_Mary   i have already seen all the episodes of foren...  \n",
       "3      FunkySweets  watched &quot;Marley and Me&quot; earlier toda...  \n",
       "4       vulcanella  @sassyback yes!!!! Oh but I'm here  sing very ...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "#patht to the dataset file\n",
    "path1 = \"C:/Users/DeepLearning/Downloads/drive-download-20191013T145900Z-001/trainingdata.csv\"\n",
    "path2 = \"C:/Users/DeepLearning/Downloads/drive-download-20191013T145900Z-001/Test-android.csv\"\n",
    "\n",
    "\n",
    "# DATASET\n",
    "DATASET_COLUMNS = [\"Sentiment\", \"ids\", \"date\", \"flag\", \"Username\", \"text\"]\n",
    "DATASET_ENCODING = \"latin-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "#dataframe\n",
    "Train = pd.read_csv(path1,dtype={\"text\": str }, encoding =DATASET_ENCODING , names=DATASET_COLUMNS, skiprows = 1)\n",
    "Test = pd.read_csv(path2,dtype={\"text\": str }, encoding =DATASET_ENCODING )\n",
    "\n",
    "\n",
    "#Making a training dataset of 140 000 values instead of 1.6 million\n",
    "#Train = Train.truncate(before=\"730 000\", after=\"870 000\")\n",
    "#Train = Train.reset_index(drop=True)\n",
    "\n",
    "Train = Train.reset_index()\n",
    "Train.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index         int64\n",
       "Sentiment     int64\n",
       "ids           int64\n",
       "date         object\n",
       "flag         object\n",
       "Username     object\n",
       "text         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 649,
     "status": "ok",
     "timestamp": 1570965608352,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "YdIaOkzG19k7",
    "outputId": "30b4f68e-782f-48eb-af18-7364d7f1b75f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>Username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2263447667</td>\n",
       "      <td>Sun Jun 21 00:50:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TANIyasso</td>\n",
       "      <td>hilo on my mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2263447702</td>\n",
       "      <td>Sun Jun 21 00:50:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mollyisabamf</td>\n",
       "      <td>@ambiiomfg Once My House Arrest Is Over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2263448097</td>\n",
       "      <td>Sun Jun 21 00:50:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Just_Plain_Mary</td>\n",
       "      <td>i have already seen all the episodes of foren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2263448360</td>\n",
       "      <td>Sun Jun 21 00:50:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>FunkySweets</td>\n",
       "      <td>watched &amp;quot;Marley and Me&amp;quot; earlier toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2263448603</td>\n",
       "      <td>Sun Jun 21 00:50:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>vulcanella</td>\n",
       "      <td>@sassyback yes!!!! Oh but I'm here  sing very ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Sentiment         ids                          date      flag  \\\n",
       "0      0          0  2263447667  Sun Jun 21 00:50:23 PDT 2009  NO_QUERY   \n",
       "1      1          0  2263447702  Sun Jun 21 00:50:23 PDT 2009  NO_QUERY   \n",
       "2      2          0  2263448097  Sun Jun 21 00:50:27 PDT 2009  NO_QUERY   \n",
       "3      3          0  2263448360  Sun Jun 21 00:50:29 PDT 2009  NO_QUERY   \n",
       "4      4          0  2263448603  Sun Jun 21 00:50:31 PDT 2009  NO_QUERY   \n",
       "\n",
       "          Username                                               text  \n",
       "0        TANIyasso                                   hilo on my mind   \n",
       "1     mollyisabamf           @ambiiomfg Once My House Arrest Is Over   \n",
       "2  Just_Plain_Mary   i have already seen all the episodes of foren...  \n",
       "3      FunkySweets  watched &quot;Marley and Me&quot; earlier toda...  \n",
       "4       vulcanella  @sassyback yes!!!! Oh but I'm here  sing very ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "26qaR6PFwrjh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6633,
     "status": "ok",
     "timestamp": 1570963768550,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "Eh5l56MRPBGv",
    "outputId": "37380f8b-941f-4f48-dde9-f8005ee24201"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hilo on my mind</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ambiiomfg Once My House Arrest Is Over</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have already seen all the episodes of foren...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched &amp;quot;Marley and Me&amp;quot; earlier toda...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sassyback yes!!!! Oh but I'm here  sing very ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Sentiment\n",
       "0                                   hilo on my mind           0\n",
       "1           @ambiiomfg Once My House Arrest Is Over           0\n",
       "2   i have already seen all the episodes of foren...          0\n",
       "3  watched &quot;Marley and Me&quot; earlier toda...          0\n",
       "4  @sassyback yes!!!! Oh but I'm here  sing very ...          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keeping only the columns wee need for sentiment analysis in Training dataset\n",
    "#train = Train.drop(columns=['ids', 'date', 'flag', 'Username' ])\n",
    "train = Train[['text', 'Sentiment']]\n",
    "train = train.dropna()\n",
    "\n",
    "#train[['text']]=train[['text']].to_string()\n",
    "train.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3825,
     "status": "ok",
     "timestamp": 1570963110629,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "2d0tLCbjP3P5",
    "outputId": "8d674186-650a-442f-a5ef-c5b64c12b47f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @otter_ai: We still have highlights from #T...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Psyk323: Lima\\r\\n&lt;U+0001F34B&gt;\\r\\n \\r\\nMy n...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Let's build a better world, no matter the cost...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey @androidstudio @AndroidDev  when I use And...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RazorSync, LLC  Android Developer  Nashville...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text Sentiment\n",
       "0  RT @otter_ai: We still have highlights from #T...          \n",
       "1  RT @Psyk323: Lima\\r\\n<U+0001F34B>\\r\\n \\r\\nMy n...          \n",
       "2  Let's build a better world, no matter the cost...          \n",
       "3  Hey @androidstudio @AndroidDev  when I use And...          \n",
       "4  RazorSync, LLC  Android Developer  Nashville...          "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keeping only the columns wee need for sentiment analysis in the Testing dataset\n",
    "\n",
    "\n",
    "test = Test[['text']]\n",
    "test = test.assign(Sentiment= \"\")\n",
    "\n",
    "test = test.dropna()\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7316,
     "status": "ok",
     "timestamp": 1570963189026,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "LFSGTHtAbgj4",
    "outputId": "cd3ff41e-4ab0-4bcf-83de-b5cbe570d883"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DeepLearning\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk import word_tokenize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @otter_ai: We still have highlights from #T...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Psyk323: Lima\\r\\n&lt;U+0001F34B&gt;\\r\\n \\r\\nMy n...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's build a better world, no matter the cost...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text Sentiment\n",
       "1  RT @otter_ai: We still have highlights from #T...          \n",
       "2  RT @Psyk323: Lima\\r\\n<U+0001F34B>\\r\\n \\r\\nMy n...          \n",
       "3  Let's build a better world, no matter the cost...          "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text = train.text.astype(str)\n",
    "test.text = test.text.astype(str)\n",
    "\n",
    "train.index = np.arange(1, len(train)+1)\n",
    "test.index = np.arange(1, len(test)+1)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessed Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframes for preprocessed training and testing data\n",
    "pretrain = train.copy()\n",
    "pretest = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R09TjcBnQYHF"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Remove stopwords\n",
    "def stopword():\n",
    "    stop=stopwords.words(\"english\")\n",
    "    pretest[\"text\"]=pretest[\"text\"].apply(lambda x:' '.join([word for word in x.split() if word not in (stop)]))#Stopword removal\n",
    "    pretrain[\"text\"]=pretrain[\"text\"].apply(lambda x:' '.join([word for word in str(x).split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BgpRtQsPZWQQ"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# Install a conda package in the current Jupyter kernel\n",
    "!conda install -c anaconda html5lib\n",
    "\n",
    "#remove special characters\n",
    "def clean(text):\n",
    "    \"\"\" Clean the text and return the cleaned text. \"\"\"\n",
    "\n",
    "    # make all letters lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove @mentions\n",
    "    text = re.sub('@[A-Za-z0-9]+', '', text)\n",
    "    \n",
    "    # remove URLs\n",
    "    text = re.sub('https?://[A-Za-z0-9./]+', '', text)\n",
    "    \n",
    "    # remove HTML encoding\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    \n",
    "    # remove punctuation, numbers, hashtag symbols\n",
    "    text = re.sub(\"[^a-zA-Z]\", ' ', text)\n",
    "    \n",
    "    # remove extra whitespaces between words\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 216809,
     "status": "error",
     "timestamp": 1570963416994,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "IbsT-gjkbsc8",
    "outputId": "0b812f9b-03b8-43a9-f7fe-c2645b4f565e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopword()\n",
    "pretrain['text'] = pretrain['text'].apply(lambda x: clean(x))\n",
    "pretest['text'] = pretest['text'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1570891630308,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "tFurqugoaraN",
    "outputId": "38fb72ac-66a4-42a8-957b-b18fad9efab6"
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "#tokenizing\n",
    "pretrain['text'] = pretrain['text'].apply(word_tokenize) \n",
    "pretest['text'] = pretest['text'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming using porterstemmer\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "pretrain['text'] = pretrain['text'].apply(lambda x: [ps.stem(i) for i in x if i != ''])\n",
    "pretest['text'] = pretest['text'].apply(lambda x: [ps.stem(i) for i in x if i != ''])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2NtiY8o8ub2"
   },
   "source": [
    "**Wordlist**\n",
    "\n",
    "Building a wordlist from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Ysj7-J7ZYSE"
   },
   "outputs": [],
   "source": [
    "#Most Common Words\n",
    "from collections import Counter\n",
    "\n",
    "words = Counter()\n",
    "for idx in pretest.index:\n",
    "    words.update(pretest.loc[idx, \"text\"])\n",
    "\n",
    "words.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q-OBPC72ZZQe"
   },
   "outputs": [],
   "source": [
    "#Wordlist from pretrain dataset\n",
    " \n",
    "\n",
    "        \n",
    "    #def build_wordlist(pretrain, \n",
    "min_occurrences=3\n",
    "max_occurences=10000\n",
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "                       #whitelist=None):\n",
    "wordlist = []\n",
    "whitelist = [\"n't\", \"not\"]\n",
    "\n",
    "        #whitelist = self.whitelist if whitelist is None else whitelist\n",
    "import os\n",
    "if os.path.isfile(\"C:/Users/DeepLearning/Downloads/drive-download-20191013T145900Z-001/wordlist.csv\"):\n",
    "    word_df = pd.read_csv(\"C:/Users/DeepLearning/Downloads/drive-download-20191013T145900Z-001/wordlist.csv\")\n",
    "    word_df = word_df[word_df[\"occurrences\"] > min_occurrences]\n",
    "    wordlist = list(word_df.loc[:, \"word\"])\n",
    "    \n",
    "\n",
    "words = Counter()\n",
    "for idx in pretrain.index:\n",
    "    words.update(pretrain.loc[idx, \"text\"])\n",
    "\n",
    "for idx, stop_word in enumerate(stopwords):\n",
    "    if stop_word not in whitelist:\n",
    "        del words[stop_word]\n",
    "\n",
    "word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "word_df.to_csv(\"C:/Users/DeepLearning/Downloads/drive-download-20191013T145900Z-001/wordlist.csv\", index_label=\"idx\")\n",
    "wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n",
    "        \n",
    "\n",
    "words = pd.read_csv(\"C:/Users/DeepLearning/Downloads/drive-download-20191013T145900Z-001/wordlist.csv\")\n",
    "x_words = list(words.loc[0:10,\"word\"])\n",
    "x_words.reverse()\n",
    "y_occ = list(words.loc[0:10,\"occurrences\"])\n",
    "y_occ.reverse()\n",
    "\n",
    "import plotly\n",
    "from plotly import graph_objs\n",
    "\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=y_occ,\n",
    "        y=x_words,\n",
    "        orientation=\"h\"\n",
    ")]\n",
    "plotly.offline.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Top words in built wordlist\")})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Bag Of Words\n",
    "we will build the bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class TwitterData_BagOfWords(TwitterData_Wordlist):\n",
    " #   def __init__(self, previous):\n",
    "  #      self.processed_data = previous.processed_data\n",
    "   #     self.wordlist = previous.wordlist\n",
    "    \n",
    "#def build_data_model():\n",
    "label_column = []\n",
    "        #if not self.is_testing:\n",
    "         #   label_column = [\"label\"]\n",
    "\n",
    "columns = label_column + list(\n",
    "    map(lambda w: w + \"_bow\", wordlist))\n",
    "labels = []\n",
    "rows = []\n",
    "for idx in pretrain.index:\n",
    "            current_row = []\n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(pretrain.loc[idx, \"text\"])\n",
    "            for _, word in enumerate(wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "data_model = pd.DataFrame(rows, columns=columns)\n",
    "data_labels = pd.Series(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = data_model.iloc[1:]\n",
    "data_model.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a label column of sentiments ('negative', 'positive', 'neutral') instead of ('0','2','4')\n",
    "def textsentiment(x):\n",
    "    if x == 0:\n",
    "        return 'Negative'\n",
    "    elif(x == 2):\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "\n",
    "label =  pretrain[\"Sentiment\"].apply(lambda x:textsentiment(x))\n",
    "labels = pd.Series(label)\n",
    "\n",
    "BOW = data_model\n",
    "BOW.insert(loc = 0, column = 'Sentiment', value = str)\n",
    "\n",
    "BOW['Sentiment']= labels\n",
    "BOW.dropna()\n",
    "BOW.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BOW = BOW.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = BOW.groupby([\"Sentiment\"]).sum()\n",
    "words_to_visualize = []\n",
    "sentiments = [\"Positive\",\"Negative\"]\n",
    "#get the most 7 common words for every sentiment\n",
    "for sentiment in sentiments:\n",
    "    words = grouped.loc[sentiment,:]\n",
    "    words.sort_values(inplace=True,ascending=False)\n",
    "    for w in words.index[:7]:\n",
    "        if w not in words_to_visualize:\n",
    "            words_to_visualize.append(w)\n",
    "            \n",
    "            \n",
    "#visualize it\n",
    "plot_data = []\n",
    "for sentiment in sentiments:\n",
    "    plot_data.append(graph_objs.Bar(\n",
    "            x = [w.split(\"_\")[0] for w in words_to_visualize],\n",
    "            y = [grouped.loc[sentiment,w] for w in words_to_visualize],\n",
    "            name = sentiment\n",
    "    ))\n",
    "    \n",
    "plotly.offline.iplot({\n",
    "        \"data\":plot_data,\n",
    "        \"layout\":graph_objs.Layout(title=\"Most common words across sentiments\")\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re as regex\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly import graph_objs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "import gensim\n",
    "\n",
    "import random\n",
    "\n",
    "seed = 666\n",
    "random.seed(seed)\n",
    "\n",
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    log(\"\")\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    log(\"Testing \" + classifier_name)\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    log(\"Learing time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    log(\"Predicting time {0}s\".format(time() - now))\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    log(\"=================== Results ===================\")\n",
    "    log(\"            Negative     Neutral     Positive\")\n",
    "    log(\"F1       \" + str(f1))\n",
    "    log(\"Precision\" + str(precision))\n",
    "    log(\"Recall   \" + str(recall))\n",
    "    log(\"Accuracy \" + str(accuracy))\n",
    "    log(\"===============================================\")\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def log(x):\n",
    "    #can be used to write to log file\n",
    "    print(x)\n",
    "    \n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(BOW.iloc[:, 1:], BOW.iloc[:, 0],\n",
    "                                                    train_size=0.7, stratify=BOW.iloc[:, 0],\n",
    "                                                    random_state=seed)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70282bce8b42a51e4d44f2c7d85c4ca9567b0fd4",
    "colab": {},
    "colab_type": "code",
    "id": "K1Mja4QAFjuu"
   },
   "outputs": [],
   "source": [
    "!pip install gensim --upgrade\n",
    "!pip install keras --upgrade\n",
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "303e72966af732ddef0bd8108a321095314e44af",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3666,
     "status": "ok",
     "timestamp": 1570699023085,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "fOspw9Z8Fju2",
    "outputId": "23fed5b6-a0d9-49b0-903e-c5a790882c48"
   },
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35e1a89dead5fd160e4c9a024a21d2e569fc89ff",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1179,
     "status": "ok",
     "timestamp": 1570699041097,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "XI-3_NDnFju9",
    "outputId": "e12f7c4f-d957-44e4-c61b-a5bfa0a409b3"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8b01a07df001e4abcc745900336c4db06e455f3",
    "colab_type": "text",
    "id": "8UhxVPHyFjvM"
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "180f0dd2a95419e4602b5c0229822b0111c826f6",
    "colab": {},
    "colab_type": "code",
    "id": "OB6J2kA-FjvO"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TEXT CLEANING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c3beecc618be68480b3d4f0de08d9d863da1dc1",
    "colab_type": "text",
    "id": "WCpQGQeCFjvS"
   },
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "563b3c44f1092dba0b853747b098e00509098cca",
    "colab_type": "text",
    "id": "Zo9pymTmFjvU"
   },
   "source": [
    "### Dataset details\n",
    "* **target**: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "* **ids**: The id of the tweet ( 2087)\n",
    "* **date**: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "* **flag**: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "* **text**: the text of the tweet (Lyx is cool)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJ_4ym84G7pX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f9a7bb129e184967b13261fb5d253af451c75c5",
    "colab_type": "text",
    "id": "dtXJc0PSFjvj"
   },
   "source": [
    "### Map target label to String\n",
    "* **0** -> **NEGATIVE**\n",
    "* **2** -> **NEUTRAL**\n",
    "* **4** -> **POSITIVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14074b59106cb9550440839e48b832223fc9502f",
    "colab": {},
    "colab_type": "code",
    "id": "MViCQXwiFjvl"
   },
   "outputs": [],
   "source": [
    "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4449d473187f647a195a6ac6986b009da32a7f4b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1485,
     "status": "ok",
     "timestamp": 1570699092066,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "5T1MKy_cFjvq",
    "outputId": "d24a41fa-299c-44b4-ffb7-1ae57cf641df"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.target = df.Sentiment.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19eb327803192f31cce3512aacb232f4d6b38715",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1566,
     "status": "ok",
     "timestamp": 1570699129196,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "8LxmQeTkFjvy",
    "outputId": "1077694c-63fb-450f-d5bc-417a45348ad2"
   },
   "outputs": [],
   "source": [
    "Sentiment_cnt = Counter(df.Sentiment)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(Sentiment_cnt.keys(), Sentiment_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4329b1573518b03e497213efa7676220734ebb4b",
    "colab_type": "text",
    "id": "HLV4vnTNFjv2"
   },
   "source": [
    "### Pre-Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8aeee8b7b9ea11b749c7f91cd4787a7b50ed1a91",
    "colab": {},
    "colab_type": "code",
    "id": "pCQQUa2iFjv4"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "649ebcb97969b9ac4301138783704bb3d7846a49",
    "colab": {},
    "colab_type": "code",
    "id": "CsIPuEG2Fjv-"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7f3e77ab9291d14687c49e71ba9b2b1e3323432",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48317,
     "status": "ok",
     "timestamp": 1570699417505,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "7q5lMHexFjwE",
    "outputId": "1a53f457-fc5e-4b69-dcfc-6ae056245866"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5f9714a8507409bbe780eebf2855a33e8e6ba37",
    "colab_type": "text",
    "id": "_DAUq1KEFjwJ"
   },
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2b1179c968e3f3910c790ecf0c5b2cbb34b0e68",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2666,
     "status": "ok",
     "timestamp": 1570699526534,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "HO3PbsfXFjwK",
    "outputId": "986728df-ec03-42ac-8ec4-158c854f8430"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f08a28aab2c3d16d8b9681a7d5d07587153a1cd6",
    "colab_type": "text",
    "id": "CkiwU3GpFjwQ"
   },
   "source": [
    "### Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2461bf564de1b4414841933d0c1d1bee5f5cc5a6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4821,
     "status": "ok",
     "timestamp": 1570699544385,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "tLXAqT82FjwR",
    "outputId": "c4e1c698-38f9-43d1-d2d2-c793466448e8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e19b9f25801ba86420decc266d2b3e6fb44f1ea",
    "colab": {},
    "colab_type": "code",
    "id": "m5LnnQCWFjwV"
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58d655af07653c594bec6bebcfb302a973b0ad9c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5124,
     "status": "ok",
     "timestamp": 1570699590185,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "GlCQFYP0Fjwa",
    "outputId": "0b1c5f6e-ed9a-4d5f-a46b-f290e6fad707"
   },
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72a5628ca81fd4b8983c12d93ae0bf950b86b6ae",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1106,
     "status": "ok",
     "timestamp": 1570700485260,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "wCrakjjKFjwh",
    "outputId": "15b4b8eb-2cd7-4aff-c405-26a843c0dd6d"
   },
   "outputs": [],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68c3e4a5ba07cac3dee67f78ecdd1404c7f83f14",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 775596,
     "status": "ok",
     "timestamp": 1570700374424,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "Uwl8_gLyFjwp",
    "outputId": "d4e9a35b-b790-4e6f-ec71-47b0b80cfadd"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27cc2651c74227115d8bfd8c40e5618048e05edd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1570700585922,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "GkJOsrz-Fjwx",
    "outputId": "94ff69f7-1631-4b93-9cb9-04dc23a8c95e"
   },
   "outputs": [],
   "source": [
    "w2v_model.most_similar(\"awesome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e13563644468037258598637b49373ca96b9b879",
    "colab_type": "text",
    "id": "0L3l88D4Fjw1"
   },
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6852bc709a7cd20173cbeeb218505078f8f37c57",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24290,
     "status": "ok",
     "timestamp": 1570700640229,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "HmO9bzTKFjw2",
    "outputId": "873ed0ac-8b97-4cd7-db55-051f4e30b38e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45de439df3015030c71f84c2d170346936a1d68f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33520,
     "status": "ok",
     "timestamp": 1570701061300,
     "user": {
      "displayName": "diae eddine Benlaghlid",
      "photoUrl": "",
      "userId": "12307951010544818882"
     },
     "user_tz": -60
    },
    "id": "F6Ug913YFjw7",
    "outputId": "f4891771-de66-46d9-d809-6def9beac100"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03b35903fc6260e190d6928d240ef7432de117fc",
    "colab_type": "text",
    "id": "PRlZW0kuFjxB"
   },
   "source": [
    "### Label Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33676e0efa39e97d89bd650b8b4eae933a22fbf0",
    "colab": {},
    "colab_type": "code",
    "id": "G02UjAA9FjxD"
   },
   "outputs": [],
   "source": [
    "labels = df_train.target.unique().tolist()\n",
    "labels.append(NEUTRAL)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04239a9bef76e7922fd86098a5601dfde8ee4665",
    "colab": {},
    "colab_type": "code",
    "id": "4a25EivDFjxH"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04299c886911ca135583ab64878f213939a2990c",
    "colab": {},
    "colab_type": "code",
    "id": "0UDvd8O0FjxM"
   },
   "outputs": [],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "232533fb27b7be99d9b8c2f8fb22c9c6bf121a6f",
    "colab": {},
    "colab_type": "code",
    "id": "xj2xYF4LFjxS"
   },
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "233c0ea94055a03e2e7df3e2a13d036ec963484f",
    "colab_type": "text",
    "id": "GFngeX7vFjxW"
   },
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ab488374b59e3f30f8b1ea92767d853c4846bac",
    "colab": {},
    "colab_type": "code",
    "id": "CfCwJt9LFjxY"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if word in w2v_model.wv:\n",
    "    embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "833279d91e4286065968237fb5f2a0c2dd4d246c",
    "colab": {},
    "colab_type": "code",
    "id": "BrF3zj__Fjxf"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b299ef78f94c2085942c993a2d58753a7476305a",
    "colab_type": "text",
    "id": "9xx4gmbGFjxn"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e775ef4f1b74e6412457181383c39f2df554ef3f",
    "colab": {},
    "colab_type": "code",
    "id": "W41sVy9kFjxr"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28d22eafd0c7d798dcf3d742bc92fb8577939e6c",
    "colab_type": "text",
    "id": "t4cXWxGYFjxx"
   },
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1331e08d590bb2aa2033706c8faca217afc0f1c3",
    "colab": {},
    "colab_type": "code",
    "id": "o3XrucY0Fjxz"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7733127cb8b380e0c807268903bf4d03ef92542",
    "colab_type": "text",
    "id": "NgSEOCw0Fjx3"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a688df590386f5748da6fe00b01904fe6c71619e",
    "colab": {},
    "colab_type": "code",
    "id": "utJcP4RoFjx5"
   },
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d0873633dd49179c8cae17377641b97d323ef3b",
    "colab_type": "text",
    "id": "qfjE6P29Fjx8"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b659d390c6577dc5cdb6b6297934279b4e801d5",
    "colab": {},
    "colab_type": "code",
    "id": "XNizHw0bFjx9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "267258196d96796ac69a7b8c466314bcf5d6ee42",
    "colab_type": "text",
    "id": "JsFfUSgQFjyB"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98ecd8f1b8b74594c3ea775dd68a094e92458022",
    "colab": {},
    "colab_type": "code",
    "id": "H7FI9JtnFjyC"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c72cd1e9d6c4fd799cbba7c813765ac4039dfc",
    "colab": {},
    "colab_type": "code",
    "id": "2e77IKbZFjyG"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bdfc0f6a6af5bebc0271d83dd7432c91001409b",
    "colab_type": "text",
    "id": "qQZILUdaFjyJ"
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0b0fa3d4b1bb14b3f5e3d169a369f3ebef29ae1",
    "colab": {},
    "colab_type": "code",
    "id": "MfBiZXIzFjyK"
   },
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed4086d651f2f8cbed11d3c909a8873607d29a06",
    "colab": {},
    "colab_type": "code",
    "id": "Dl_GZwW0FjyO"
   },
   "outputs": [],
   "source": [
    "def predict(text, include_neutral=True):\n",
    "    start_at = time.time()\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = model.predict([x_test])[0]\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score),\n",
    "       \"elapsed_time\": time.time()-start_at}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca38b1e6c9b5acfed7467de2cf02a78333108872",
    "colab": {},
    "colab_type": "code",
    "id": "bCWyfR4EFjyc"
   },
   "outputs": [],
   "source": [
    "predict(\"I love the music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e5fe647533be0148850de349fea6ef6f71303d1",
    "colab": {},
    "colab_type": "code",
    "id": "dUnYbOKQFjyg"
   },
   "outputs": [],
   "source": [
    "predict(\"I hate the rain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37064dffcc8920d34ccd54fac7c8b50e583a8269",
    "colab": {},
    "colab_type": "code",
    "id": "bGqrt7q9Fjyw"
   },
   "outputs": [],
   "source": [
    "predict(\"i don't know what i'm doing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ee72e47f84b6dbc32e02a783de5ec1661f157e1",
    "colab_type": "text",
    "id": "37oO4S8KFjzO"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e920173eb05f04aecdd735bc5dff0f5be5f8d15",
    "colab": {},
    "colab_type": "code",
    "id": "ym3cIuCcFjzU"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_1d = []\n",
    "y_test_1d = list(df_test.target)\n",
    "scores = model.predict(x_test, verbose=1, batch_size=8000)\n",
    "y_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3575191bb425ab871f3f41e83812ee84bb7e595",
    "colab": {},
    "colab_type": "code",
    "id": "owYB8RneFjzZ"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a57dc6f6211c144491a70f533225edfa95a2dc66",
    "colab": {},
    "colab_type": "code",
    "id": "yljeXEo_Fjzm"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=df_train.target.unique(), title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e23b957348dcc084249d3cc7538b972da471c2cd",
    "colab_type": "text",
    "id": "1WXftM9tFjz9"
   },
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7fe05b7caa1c984ff1deb0be2f7c6bc043df9f5",
    "colab": {},
    "colab_type": "code",
    "id": "G7Zw9nryFjz-"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4eb300f0c6693a618587c7dcf32f77f5416cbfb9",
    "colab_type": "text",
    "id": "JnVQSCwOFj0Q"
   },
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5cf76e6e09f8a60ed25947932b94c772eda44d23",
    "colab": {},
    "colab_type": "code",
    "id": "3VL2JrtTFj0R"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test_1d, y_pred_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f014c32f3833db282e1a075c526604f34e3158c",
    "colab_type": "text",
    "id": "W6VAXyRNFj0X"
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b2b3ad5b592977b404acfa1c9ad303a62837255",
    "colab": {},
    "colab_type": "code",
    "id": "ib_TdiMQFj0Y"
   },
   "outputs": [],
   "source": [
    "model.save(KERAS_MODEL)\n",
    "w2v_model.save(WORD2VEC_MODEL)\n",
    "pickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\n",
    "pickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc363c54782894757f5ea8820c6a170f2e16ef93",
    "colab": {},
    "colab_type": "code",
    "id": "wkllgll3Fj0c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Attachments",
  "colab": {
   "collapsed_sections": [
    "WCpQGQeCFjvS",
    "Zo9pymTmFjvU"
   ],
   "machine_shape": "hm",
   "name": "twitter-sentiment-analysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:AzureML] *",
   "language": "python",
   "name": "conda-env-AzureML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
